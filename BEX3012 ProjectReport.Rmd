---
title: "BEX3012 Project Report \n Detecting Facial Expressions in Professional Tennis Matches"
author: "Stephanie Kobakian"
date: "28 March 2017"
output: bookdown::pdf_document2
fig_caption: yes
fontsize: 11pt
link-citations: true
---


```{r cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = F, warning = F)

library(tidyverse)
library(readr)

#EmoM <-read_csv("data/EmotionsMerged.csv")
ME <- read_csv("data/MicrosoftEmotions.csv")
SB<-read_csv("data/SkybiometryEmotions.csv")
GE<- read_csv("SoftwareRequestScripts/GoogleClassifiedFaces.csv")
EmotionSoftwareSpecs<-read_csv("TableCSVs/EmotionSoftwareSpecifications.csv")
ALLmetaIMGnamed <- read_csv("data/ALLmetaIMGnamed.csv")

#Create normalised SB values
sumf <- function(vec) sum(vec)

SB<-SB %>%
  rowwise %>%
  mutate(z = sumf(c(anger.confidence, disgust.confidence, fear.confidence, happiness.confidence, neutral_mood.confidence, sadness.confidence, surprise.confidence,  na.rm=T)))

SB<-SB %>%
  mutate(anger = anger.confidence/z,
         disgust = disgust.confidence/z,
         fear = fear.confidence/z,
         happiness = happiness.confidence/z,
         neutral = neutral_mood.confidence/z,
         sadness = sadness.confidence/z,
         surprise = surprise.confidence/z)

```


# Introduction

Facial Recognition is beginning to be explored in sports environments, this presents quality issues.


helpful for applications



# Method
## Materials
### Image Set
A subset of faces was created specifically for emotion recognition purposes. This set contains faces that were manually annotated as players.
It contains the area within the face bounding boxes found in the previous study, as well as a small border to fram the face. This resulted in images of differing sizes to be passed to the APIs.
These images were hosted on Google Drive to allow for URL access from the API to the individual images.

### Software APIs

We will consider three Emotion Recognition softwares.


```{r Emotion-Software-Specs-Table, echo=F, fig.cap = "\\label{tab:Emotion-Software-Specs-Table}"}

knitr::kable(EmotionSoftwareSpecs, longtable=TRUE, booktabs = TRUE, caption="This details the capabilities we considered important in recognising emotions in images of faces.")
```


As can be seen above, a noticable difference between the three is the amount of times the API can be called. Skybiometry had the largest imposition on Bath Processing as it only allowed 100 API calls to be processed per hour. Microsoft also had a limit imposed, but this allowed for much more to be processed with the possibility of 1200 images to be processed within an hour, after accounting for the wait time betwwen each group of 20.
Google Vision's API batch processing limit had a minimal effect.


The range of outputs from the softwares is displayed as Google provides likelihoods of an emotion occuring on a particular face. Microsoft and Skybiometry provide outputs on the same emotions^[Based on Paul Ekmans emotion theories]. However the values that they provide differ as Microsoft provide Porportions whereas Skybiometry results in a Confidence of the emotion occuring in the specified face.



```{r Outputs, echo=F, fig.cap = "\\label{tab:Emotion-Software-Specs-Table}"}

GE[706,c(1,10:13)]

SB[6,1:19]

ME[6,1:9]


```











